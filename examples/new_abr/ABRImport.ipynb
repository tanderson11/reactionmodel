{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo:\n",
    "# transmission terms as second order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from reactionmodel.model import Species\n",
    "from reactionmodel.hook import HookAwareModel\n",
    "import reactionmodel.parser as parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load arrows from the excel document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_columns(df, columns, parentheses=True, sep='*', na_rep=None):\n",
    "    df = df[columns].copy()\n",
    "    if parentheses:\n",
    "        df['left'] = '('\n",
    "        df['right'] = ')'\n",
    "    else:\n",
    "        df['left'] = ''\n",
    "        df['right'] = ''\n",
    "    for c in columns:\n",
    "        df[c] = df['left'].str.cat(df[c]).str.cat(df['right'])\n",
    "    \n",
    "    first_col = df[columns[0]]\n",
    "    later_cols = df[columns[1:]]\n",
    "    return first_col.str.cat(later_cols, sep=sep, na_rep=na_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrows_file = pd.ExcelFile('./Shared model arrows.xlsx')\n",
    "arrows = arrows_file.parse('Reactions').drop(0)\n",
    "arrows = arrows[arrows['Include'].astype(bool)]\n",
    "arrows['Initial'] = arrows['Initial (A)'].str.cat(arrows['Initial (N)'], sep='_')\n",
    "arrows['Final'] = arrows['Final (A)'].str.cat(arrows['Final (N)'], sep='_')\n",
    "\n",
    "arrows['Initial'] = arrows['Initial'].str.replace('-_-', '')\n",
    "arrows['Final'] = arrows['Final'].str.replace('-_-', '')\n",
    "# It's dumb, but k stem is guaranteed non-blank where Description (ie not Description stem) is guaranteed non-blank\n",
    "arrows['k'] = concatenate_columns(arrows, ['k stem', 'k']).fillna(arrows['k stem'])\n",
    "arrows['Description'] = concatenate_columns(arrows, ['Description stem', 'Description'], sep=' ', parentheses=False).fillna(arrows['Description'])\n",
    "\n",
    "arrows = arrows[['Group', 'Description', 'Initial', 'Final', 'k', 'trigger']]\n",
    "\n",
    "arrows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse file into a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROBLEM: DSDR can't exist in high abundance\n",
    "families = {\n",
    "    'star': ['M', 'X', 'DS', 'DR', 'DSDR']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arrow(arrow):\n",
    "    family_flag = False\n",
    "\n",
    "    if pd.isna(arrow.trigger):\n",
    "        arrow_dictionary = {'k': arrow.k}\n",
    "    else:\n",
    "        arrow_dictionary = {'p': arrow.k}\n",
    "\n",
    "    reactants = arrow.Initial\n",
    "    if reactants.count('*') > 1: assert False\n",
    "    elif reactants.count('*') == 1: family_flag = True\n",
    "    reactants = reactants.replace('*', '$i')\n",
    "\n",
    "    products = arrow.Final\n",
    "    if products.count('*') > 1: assert False\n",
    "    elif products.count('*') == 1: family_flag = True\n",
    "    products = products.replace('*', '$i')\n",
    "\n",
    "    reactants = [reactants] if reactants else []\n",
    "    products = [products] if products else []\n",
    "\n",
    "    arrow_dictionary.update({\n",
    "        'description': arrow.Description,\n",
    "        'reactants': reactants,\n",
    "        'products': products,\n",
    "    })\n",
    "\n",
    "    if family_flag:\n",
    "        arrow_dictionary['used_families'] = {'i': 'star'}\n",
    "\n",
    "    return arrow_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "reactions = []\n",
    "triggered_sets = defaultdict(lambda: [])\n",
    "\n",
    "for i, arrow in arrows.iterrows():\n",
    "    destination = reactions\n",
    "    if not pd.isna(arrow.trigger):\n",
    "        destination = triggered_sets[arrow.Group]\n",
    "\n",
    "    arrow_dictionary = parse_arrow(arrow)\n",
    "    destination.append(arrow_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_df = arrows_file.parse('Species')\n",
    "base_species = [Species(s.Name, description=s.Description) for _,s in species_df.fillna('').iterrows()]\n",
    "\n",
    "bad_species = [\n",
    "    {'name':'DS_M'},\n",
    "    {'name':'DS_X'},\n",
    "    {'name':'DS_DR'},\n",
    "    {'name':'DR_M'},\n",
    "    {'name':'DR_X'},\n",
    "    {'name':'DR_DS'},\n",
    "    {'name':'X_M'},\n",
    "    {'name':'DSDR_DSDR'},\n",
    "    {'name':'DSDR_DS'},\n",
    "    {'name':'DSDR_DR'},\n",
    "]\n",
    "bad_species = [Species(**s) for s in bad_species]\n",
    "\n",
    "species = [s.to_dict() for s in base_species] + [s.to_dict() for s in bad_species]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dictionary = {\n",
    "    'families': families,\n",
    "    'species': species,\n",
    "    'reactions': reactions,\n",
    "    'triggered_sets': triggered_sets\n",
    "}\n",
    "\n",
    "results = parser.loads(model_dictionary, model_class=HookAwareModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_reactions = [r for r in results.model.all_reactions if not set(r.reactants).intersection(bad_species) and not set(r.products).intersection(bad_species)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_model = HookAwareModel(\n",
    "    base_species,\n",
    "    [r for r in results.model.all_reactions if not set(r.reactants).intersection(bad_species) and not set(r.products).intersection(bad_species)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = arrows_file.parse('Parameters')[['Parameter', 'Value']].set_index('Parameter').to_dict()['Value']\n",
    "## At some point here evaluate the rate constants at the parameters\n",
    "\n",
    "needs_pressure_ds = [i for i,r in enumerate(filtered_model.all_reactions) if 'PRESSURE_DS' in r.k]\n",
    "needs_pressure_dr = [i for i,r in enumerate(filtered_model.all_reactions) if 'PRESSURE_DR' in r.k]\n",
    "\n",
    "parameters.update({'PRESSURE_DS': 1, 'PRESSURE_DR': 1})\n",
    "\n",
    "all_k = filtered_model.get_k(parameters=parameters)\n",
    "assert(isinstance(all_k, np.ndarray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from reactionmodel.model import eval_expression\n",
    "\n",
    "s_df = species_df.set_index('Name')\n",
    "pressure_ds_vec = np.zeros(len(filtered_model.species))\n",
    "pressure_dr_vec = np.zeros(len(filtered_model.species))\n",
    "\n",
    "for i,s in enumerate(filtered_model.species):\n",
    "    pressure_ds_vec[i] = eval_expression(str(s_df.loc[s.name]['PRESSURE_DS']), parameters)\n",
    "    pressure_dr_vec[i] = eval_expression(str(s_df.loc[s.name]['PRESSURE_DR']), parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "needs_pressure_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "needs_pressure_dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit as numbajit\n",
    "\n",
    "parametrized_reactions = []\n",
    "for i,rxn in enumerate(filtered_model.all_reactions):\n",
    "    k = all_k[i]\n",
    "    if i in needs_pressure_ds:\n",
    "        assert i not in needs_pressure_dr\n",
    "        @numbajit(nopython=True)\n",
    "        def pressure_ds(t, y):\n",
    "            return np.sum(y * pressure_ds_vec)\n",
    "        k = pressure_ds\n",
    "    elif i in needs_pressure_dr:\n",
    "        assert i not in needs_pressure_ds\n",
    "        @numbajit(nopython=True)\n",
    "        def pressure_dr(t, y):\n",
    "            return np.sum(y * pressure_dr_vec)\n",
    "        k = pressure_dr\n",
    "    existing_dict = rxn.to_dict(keep_species_objects=True)\n",
    "    existing_dict.update({'k': k})\n",
    "    parametrized_reactions.append(type(rxn)(**existing_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametrized_reactions = [r for r in parametrized_reactions if r.k != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_model.all_reactions), len(parametrized_reactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametrized_model = HookAwareModel(\n",
    "    base_species,\n",
    "    parametrized_reactions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametrized_model.get_propensities_function(jit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
